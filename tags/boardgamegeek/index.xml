<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>BoardGameGeek on Analysis Paralysis</title>
    <link>https://recommend-games.github.io/tags/boardgamegeek/</link>
    <description>Recent content in BoardGameGeek on Analysis Paralysis</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>contact@recommend.games (Recommend.Games)</managingEditor>
    <webMaster>contact@recommend.games (Recommend.Games)</webMaster>
    <lastBuildDate>Thu, 11 Apr 2024 20:00:00 +0300</lastBuildDate>
    <atom:link href="https://recommend-games.github.io/tags/boardgamegeek/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Has board game rating inequality increased over the years?</title>
      <link>https://recommend-games.github.io/posts/gini/</link>
      <pubDate>Thu, 11 Apr 2024 20:00:00 +0300</pubDate><author>contact@recommend.games (Recommend.Games)</author>
      <guid>https://recommend-games.github.io/posts/gini/</guid>
      <description>The number of ratings per game Perhaps one of the more controversial choices of the Shut Up &amp;amp; Sit Down Effect article was using the number of ratings on BoardGameGeek (BGG) as proxy for &amp;ldquo;attention&amp;rdquo; to a game. So let&amp;rsquo;s double down on that! ðŸ˜ˆ&#xA;If lots of ratings mean a lots of eyes on a game, we can ask questions like: What games get all the attention? Do few games steal the spotlight?</description>
    </item>
    <item>
      <title>Reverse engineering the BoardGameGeek ranking â€“ Part 2!</title>
      <link>https://recommend-games.github.io/posts/reverse-engineering-boardgamegeek-ranking-part-2/</link>
      <pubDate>Tue, 26 Jan 2021 22:24:00 +0200</pubDate><author>contact@recommend.games (Recommend.Games)</author>
      <guid>https://recommend-games.github.io/posts/reverse-engineering-boardgamegeek-ranking-part-2/</guid>
      <description>This is the second part of a series explaining and analysing the BoardGameGeek rankings. Read the first part here.&#xA;Last time I left you with the nice result that BoardGameGeek (BGG) calculates its ranking by taking users&amp;rsquo; ratings for a particular game and then add around 1500-1600 dummy ratings of 5.5. This so-called geek score is used to sort the games from best (Gloomhaven) to worst (Tic-Tac-Toe).&#xA;One detail however we touched on in passing, but did not resolve, is how that number of dummy ratings develop over time.</description>
    </item>
    <item>
      <title>Reverse engineering the BoardGameGeek ranking</title>
      <link>https://recommend-games.github.io/posts/reverse-engineering-boardgamegeek-ranking/</link>
      <pubDate>Sat, 03 Oct 2020 08:42:51 +0300</pubDate><author>contact@recommend.games (Recommend.Games)</author>
      <guid>https://recommend-games.github.io/posts/reverse-engineering-boardgamegeek-ranking/</guid>
      <description>TL;DR: BoardGameGeek calculates its ranking by adding around 1500-1600 dummy ratings of 5.5 to the regular users&amp;rsquo; ratings. They called it their geek score, statisticians call it a Bayesian average. We use this knowledge to calculate some alternative rankings.&#xA;I often describe BoardGameGeek (BGG) as &amp;ldquo;the Internet Movie Database (IMDb) for games&amp;rdquo;. Much like its cinematic counterpart, the biggest board game database not only collects all sorts of information obsessively, but also allows users to rate games on a scale from 1 (awful - defies game description) to 10 (outstanding - will always enjoy playing).</description>
    </item>
  </channel>
</rss>
